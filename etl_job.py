# -*- coding: utf-8 -*-
"""ETL_JOB.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1y6JFrl0SptpFwacH_GzsMlwSiUrTa57o
"""

import os
os.chdir('/content/drive/MyDrive/Kagge_colab/dbda-proj')

import pandas as pd
import numpy as np
import re

df = pd.read_excel('IndianFoodDatasetXLS.xlsx')

df.head()

# Clean the TranslatedIngridents column
def clean_ingredients(row):
    if isinstance(row, str):  # Check if the row is a string
        ingredients = row.split(',')
        cleaned_ingredients = [ingredient.strip() for ingredient in ingredients]
        return cleaned_ingredients
    else:
        return []

df['CleanedIngredients'] = df['TranslatedIngredients'].apply(clean_ingredients)

def clean_text(item):
    cleaned_text = re.sub(r'[^a-zA-Z\s]', '', item)
    return cleaned_text

only_ingredients = df['CleanedIngredients'].apply(lambda row: [clean_text(item) for item in row])

def clean_and_convert(elements):
    cleaned_elements = [element.strip().replace('  ', ' ') for element in elements]
    return cleaned_elements

# Apply the clean_and_convert function to each list in the 'CleanedIngredients' column
df['ProcessedIngredients'] = only_ingredients.apply(clean_and_convert)

split_ingredients = [word for ingredient in df['ProcessedIngredients'][0] for word in ingredient.split()]

df_split =df['ProcessedIngredients'].apply(lambda row: [word for ingredient in row for word in ingredient.split()])

df['ProcessedCleanedIngredients']=df_split

df['ProcessedCleanedIngredients']=df_split
def is_empty_list(lst):
    return len(lst) == 0

# Apply the is_empty_list function to the 'SplitAndLowercase' column
isEmpty= df['ProcessedCleanedIngredients'].apply(is_empty_list)

empty_indices_list = isEmpty[isEmpty].index.tolist()

empty_rows = df.loc[empty_indices_list]

clear_df=df.drop(empty_indices_list)

def split_and_lowercase(row):
    split_row = [word.lower() for ingredient in row for word in ingredient.split()]
    return split_row

lower= df['ProcessedCleanedIngredients'].apply(split_and_lowercase)

clear_df['ProcessedCleanedLoweredIngredients']=lower

stop_words=['thinly','sliced','teaspoons','teaspoon','as','inch','per','required',
            'a','pinch','use','cup','chopped','or','taste','cups','kg','grams',
            'tablespoon','tablespoons','medium','pieces','cooked','recipe','below','to',
            'for','cooking','cut','into','paste','long','and','finely','thin','whole','softened','sweet','spicy','homemade','small','cubes',
            'full','few','mixed','roughly','split','dry','broken','raw','squeezed','spoon','powder','tbsp','any','other','tsp','seeds',
            'soaked','of','in','all','frying','directly','inches','wedges','yellow','diced','white','needed','slit',
            'grated','friendly','cholestrol','omit','virgin','extra',
            'thick','make','stock','night','over','broad','slits','optional',
            'shredded','purple','leaves','leaves','mix','red',
            'sunflower', 'green', 'leaf', 'stick', 'puree', 'sauce', 'juice', 'roasted', 'bengal', 'black',
            'fresh', 'ripe', 'room', 'temperature', 'extract', 'purpose', 'whipping', 'dark', 'greek', 'at',
            'garnish', 'demerara', 'unsalted', 'hung', 'powdered', 'dessicated', 'icing', 'washed',
            'strands','heavy', 'crushed', 'breasts', 'kashmiri', 'dried', 'mashed', 'kala']

def stop_removal(lst):
  no_stop=[]
  for word in lst:
    if word not in stop_words:
      no_stop.append(word)
  return no_stop

final_ingredients=clear_df['ProcessedCleanedLoweredIngredients'].apply(lambda x: stop_removal(x))

final_ingredients[890]

clear_df['ProcessedCleanedLoweredIngredientsFiltered']=final_ingredients

def filter_name(rows):
  cleaned_text = re.sub(r'[^a-zA-Z\s()]', '', rows)
  return cleaned_text

clear_df['EnglishRecepie']=clear_df['TranslatedRecipeName'].apply(lambda x : filter_name(x))

clear_df['Cuisine']=clear_df['Cuisine'].apply(lambda x : filter_name(x))

alergens=['Milk'
,'Peanuts'
,'Groundnuts'
,'Eggs'
,'Fish'
,'Mushroom'
,'Soyabean'
,'Sesame'
,'Corn'
,'Paneer','cottage','cheese'
,'Chickpea'
,'eggplant','brinjal'
,'Banana'
,'mustard'
,'shrimp','Prawn'
,'kiwi'
,'carrot'
,'poppy seeds'
,'sunflower seeds'
,'apple'
,'grape'
,'mango'
,'pork'
,'beef'
,'chicken'
,'peach'
,'dahi','curd','yogurt'
,'ghee'
,'butter'
,'almonds'
,'walnut']

list1=[elem.lower() for elem in alergens]

def alergens_detection(x,list1):
  heh=[]
  for word in x:
    if word in list1:
      heh.append(word)
  return heh

clear_df['common_alergens']=clear_df['ProcessedCleanedLoweredIngredients'].apply(lambda x: alergens_detection(x,list1))

clear_df['common_alergens']

def remove_duplicates(row):
    return list(set(row))

# Apply the remove_duplicates function using lambda

clear_df['common_alergens'] = clear_df['common_alergens'].apply(lambda x: remove_duplicates(x))

clear_df.columns

# Clean the TranslatedIngridents column
def clean_ingredients(row):
    if isinstance(row, str):  # Check if the row is a string
        ingredients = row.split(',')
        cleaned_ingredients = [ingredient.strip() for ingredient in ingredients]
        return cleaned_ingredients
    else:
        return []

def tag_ingredients(row):
    if isinstance(row, str):  # Check if the row is a string
        ingredients = row.split(',')
        cleaned_ingredients = [ingredient.strip() for ingredient in ingredients]
        return ', '.join(cleaned_ingredients)  # Join the cleaned ingredients into a single string
    else:
        return ''

clear_df['CleanedIngredients'] = clear_df['TranslatedIngredients'].apply(clean_ingredients)
clear_df['TaggedIngredients'] = clear_df['TranslatedIngredients'].apply(tag_ingredients)

def remove_commas(text):
    return text.replace(',', '')

clear_df['StringCleanedIngredients']=clear_df['TaggedIngredients'].apply(lambda x: remove_commas(x))

def clean_ingredients(item):
    cleaned_text = re.sub(r'[^a-zA-Z\s]', '', item)
    cleaned_text = re.sub(r'\s+', ' ', cleaned_text)
    return cleaned_text

clear_df['StringCleanedFilteredIngredients']=clear_df['StringCleanedIngredients'].apply(lambda x : clean_ingredients(x))
clear_df['StringCleanedLowerIngredients'] = clear_df['StringCleanedFilteredIngredients'].apply(lambda x: x.lower())

# Define your custom list of stopwords
stop_words=['thinly','sliced','teaspoons','teaspoon','as','inch','per','required',
            'a','pinch','use','cup','chopped','or','taste','cups','kg','grams',
            'tablespoon','tablespoons','medium','pieces','cooked','recipe','below','to',
            'for','cooking','cut','into','paste','long','and','finely','thin','whole','softened','sweet','spicy','homemade','small','cubes',
            'full','few','mixed','roughly','split','dry','broken','raw','squeezed','spoon','powder','tbsp','any','other','tsp','seeds',
            'soaked','of','in','all','frying','directly','inches','wedges','yellow','diced','white','needed','slit',
            'grated','friendly','cholestrol','omit','virgin','extra',
            'thick','make','stock','night','over','broad','slits','optional',
            'shredded','purple','leaves','leaves','mix','red', 'minced', 'peeled', 'with','cook', 'bake', 'roast', 'fry', 'saut√©', 'simmer', 'boil'
            , 'ounce', 'gram', 'milliliter', 'liter', 'dash', 'dish', 'cuisine', 'meal'
]

# Function to remove custom stopwords from a text
def remove_custom_stopwords(text):
    # Split the text into words and filter out custom stopwords
    words = text.split()
    filtered_words = [word for word in words if word.lower() not in stop_words]
    return ' '.join(filtered_words)

# Assuming your DataFrame is named clear_df and the column is 'StringCleanedLowerIngredients'
clear_df['StringCleanedLowerIngredientsFiltered'] = clear_df['StringCleanedLowerIngredients'].apply(remove_custom_stopwords)

clear_df.columns

clear_df['Srno']

clear_df['Srno']= range(1, len(clear_df) + 1)
clear_df['Srno']

cols=['Srno','EnglishRecepie','FlavourProfile','PrepTimeInMins','CookTimeInMins','TotalTimeInMins','Servings','Diet','Course','Cuisine','Region',
                    'StringCleanedLowerIngredientsFiltered','ProcessedCleanedLoweredIngredientsFiltered','common_alergens','URL']

cleaned_df=clear_df[cols]

cleaned_df

